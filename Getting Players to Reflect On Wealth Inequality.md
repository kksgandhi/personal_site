---
id: Getting Players to Reflect On Wealth Inequality
aliases: []
tags: []
---

[Other People's Money](https://kksgandhi.itch.io/other-peoples-money) is an award winning game asking players to reflect on wealth inequality and our priorities as a society. Throughout the game the player encounters bits of text, snippets that provide information and prompt the player to reflect.

The game was iteratively designed to incorporate [[Other People's Money background research|best practices in the communication of wealth inequality]]. The game has the following transformational goals:

  - Disposition: Players more positively favor reasonably expensive large projects, possibly via taxation.
  - Knowledge: Players better understand what an order of magnitude is, and how large projects that all seem "expensive" can still be separated by orders of magnitude.
  - Behavior: When players encounter a news article or discussion about a project, they will be more likely to logically reason about its cost, rather than simply categorize it as "expensive".

The main question of this project is whether the text snippets are worth it, and if so, for which audience do they work? On the one hand, the text encourages reflection, on the other hand, it might annoy players. Below are some preliminary notes from 17 playtests. These playtesters were given a version of the game (either a version with these reflective text snippets or without them) completed exercises, answered playtest questions, and then played the other version of the game.

Future work will involve a deeper analysis of the playtests along with a larger-scale online study with (ideally) hundreds of playtesters, to get enough data for inferential statistical analysis.

Preliminary Playtest Notes
--------------------------

As expected from pilot playtesting, the monetary visualization was powerful and shocking. Every participant discussed being surprised and intrigued by the juxtaposed costs. Many participants remembered specific expenditures or classes of expenditure as more or less than expected. (e.g. “Fixing the crisis in Flint, Michigan is so cheap!” or “Infrastructure costs more than I thought it would”). Many participants also mentioned feeling frustrated or disgusted that cheap problems were being ignored by society.

The results of the exercises weren’t really what I expected. For the attitudes questions (i.e. Do you think the government ought to normalize incomes, Are people rewarded for their skills…), people tended not to vary too much from their registered answers. They often didn’t refer to the game or the bridging text in the game, and if they did, it seemed like the game didn’t change their views as much as it reminded them about their existing views. This could possibly be a ceiling effect (our participants were already inclined to favor wealth redistribution). 

Similarly, with the activities (e.g. How much does NASA cost, how much does highway upkeep cost), people’s answers were repeatedly just wild guesses, both during registration and during the post-gameplay questions. There wasn’t much to analyze regarding a change in “guessing technique,” because participants were just guessing a somewhat reasonable number. When participants did mention the game, it could have been chalked up to an anchoring effect rather than true change. (Players “anchored” their guesses to the order of magnitude presented in the game. There was one player who answered all the questions as somewhere in the millions during registration. They then played the game and answered in the billions, claiming that the game had put them in “a billions mindset”).

Players were very positive about the bridging text. Because the sessions went pretty quickly, I usually had time to show the with-text version of the game to participants in the non-text condition (once everything else in the study was done, of course). Players mentioned how it channeled their thoughts, served as a good call to action, created interesting questions, and inspired them to learn more. There was nuance of course, participants were sometimes concerned that the text may not work with other players, or that an in person conversation would be better, talking about how the game should be played as part of a workshop. A few participants didn’t like the text, for example, one participant thought the conclusions of the game were more powerful when one came to those conclusions themselves, while another felt like the text was too subjective.
