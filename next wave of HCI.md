At *CSCW* 2019, I had the opportunity to have a wonderful talk with Dr. *Reinecke* from the University of Washington about this very topic. The question I asked was about the "future proofing" of [HCI](HCI.md). Many of the papers I was reading were very specifically in regards to technology that existed at the time. For example, the paper Dr. Reinecke was presenting was about the accessibility of Uber in indigenous areas. *Uber* has only been around for 11 years, and within those years it has changed wildly both in its internal structure and its scope. To me, it felt like it was entirely feasible that Dr. Reinecke's entire work could be made useless if more drivers suddenly signed up in indigenous areas. Uber is currently working on self driving cars (https://www.uber.com/us/en/atg/technology/). It's similarly feasible that success in this initiative would mean that Uber cars are accessible everywhere, since the barrier of entry to installing a self driving car wouldn't be that much, and they could easily be installed in primarily indigenous areas.

I asked Dr. Reinecke how she felt about what I had mentioned above in regards to *future proofing*. Her response boiled down to this: Lots of HCI research will become mostly unusable due to shifting technology, but each piece of work will uncover something core and unchanging in regards to human nature and HCI. Even if Uber changes its policies and indigenous citizens are granted more access, studying how Uber interacts with these populations still says something valuable about how modern majority populations treat minority indigenous populations and how tech companies perpetuate these issues. She mentioned how well written papers often indicate this, how their work is unique to the technology of the time, and what the broader, non technologically bound implications are.

Technological progress exists on an exponential curve, and thus *technological progress* will come faster and faster as time passes. I see the next overarching problem in HCI to be this idea of "future proofing". Of taking HCI concepts that have been well studied, and seeing what aspects of them are core to human nature (and will thus stay around for as long as there are humans) and what concepts are problems in HCI simply because of the technology of the time. 

Let me use a concrete example: At the same CSCW conference, another thing I heard quite a few times was discussion about *teleconferencing*, whether through audio modes (telephone) or video modes (video chat). I repeatedly heard that audio only teleconferencing didn't work that well since people could not see each other's facial cues. Video conferencing was better, but still a stopgap measure, and many of the CSCW attendees lamented that physical interaction was still unmatched.

In my subjective experience, video conferencing has gone from a new and relatively uncommon technology to a technology that's viable to use for practically every meeting (even disregarding Covid). It's plausible that the same could happen with VR, or other more immersive conferencing platforms. If this is the case, it means that decades of work about the problems with audio conferencing will need to be recontextualized. We'll need to ask what value these works bring if VR has solved many of the issues with teleconferencing.

Now I'd like to make it clear: I completely recognize that HCI researchers understand how future technologies could potentially affect their current work. I'm not saying that this is a failure of HCI at the moment. What I am saying is that, as technologies change faster and faster, it'll become a larger problem in the HCI community, and researchers will become more explicit about it. 

What would this actually look like? I imagine that alongside the "limitations" section of a work, there would be a section acknowledging how up and coming technologies might affect the outcomes of a work. These sections would be predictions by the authors about how (if the technologies pan out) these new technologies would affect (or not affect) certain aspects of the paper. Meta analyses and literature reviews would discuss the general and timeless implications of the papers they analyze, without going into specifics about the technology.
