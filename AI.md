AI is split into [[symbolic AI]], which uses rules to figure out how to act, and [[machine learning]], which acts on data. Supervised machine learning tries to mimic data it is given (if it's given images labeled "dog" and "cat", it will try to learn the patterns and classify future images into "dog" or "cat"). Unsupervised machine learning draws patterns and points out interesting things in data it is given.

 - [3 Blue 1 Brown's video on how supervised learning AI works, which is what is used in things like ChatGPT](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
AI is difficult to reason about because people tend to anthropomorphize things too much, seeing intelligence where there isn't any. At the same time, people have an anti-[[mechanistic bias]], assuming that there is something fundamentally non-mechanical about humans, something that a mechanical system could never reproduce.

Obviously, this means thinking about [[AI safety]] is hard.
